{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f054173-181d-499c-bb06-e73be914d12d",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24e78c-4b07-4404-9084-d2a06e9e8978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from h_population.csv and generated_synthetic_data_WGAN.csv...\n",
      "\n",
      "=== Data Summary ===\n",
      "Population data: 1,066,319 rows, 13 columns\n",
      "Generated data: 1,066,319 rows, 13 columns\n",
      "\n",
      "Calculating SRMSE...\n",
      "SRMSE for marginal distributions: 0.0319\n",
      "SRMSE for bivariate distributions: 0.0944\n",
      "\n",
      "Calculating precision and recall...\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "Precision: 0.8139\n",
      "Recall: 0.8079\n",
      "F1 Score: 0.8109\n",
      "\n",
      "=== Unique Combinations Analysis ===\n",
      "Population unique combinations: 264,005\n",
      "Generated unique combinations: 263,925\n",
      "\n",
      "=== Matching Combinations Analysis ===\n",
      "Precision) Total rows in generated data: 1,066,319\n",
      "Precision) Rows matching the population: 867,849\n",
      "Precision) Percentage of rows matching: 81.39%\n",
      "Recall   ) Total unique combinations in generated data: 263,925\n",
      "Recall   ) Unique combinations matching the population: 111,562\n",
      "Recall   ) Percentage of unique combinations matching: 42.27%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def SRMSE(x_population, resamples):\n",
    "    \"\"\"\n",
    "    Function to calculate SRMSE (Standardized Root Mean Square Error)\n",
    "    - Calculates SRMSE for marginal and bivariate distributions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_population : DataFrame\n",
    "        Original population DataFrame\n",
    "    resamples : DataFrame\n",
    "        Generated synthetic population DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        [srmse_mar, srmse_bi] — SRMSE for marginal and bivariate distributions\n",
    "    \"\"\"\n",
    "    # ── Marginal distribution ───────────────────────────────\n",
    "    sam_marg_cnt = []\n",
    "    resam_marg_cnt = []\n",
    "    for col in x_population.columns:\n",
    "        pop_series = x_population[col].dropna()\n",
    "        syn_series = resamples[col].dropna()\n",
    "\n",
    "        resam = syn_series.value_counts().sort_index()\n",
    "        sam = pop_series.value_counts().sort_index()\n",
    "        tab = pd.merge(resam, sam, left_index=True, right_index=True, how='outer').fillna(0)\n",
    "        sam_prop = tab.iloc[:, 1].values / pop_series.shape[0] if pop_series.shape[0] > 0 else 0\n",
    "        resam_prop = tab.iloc[:, 0].values / syn_series.shape[0] if syn_series.shape[0] > 0 else 0\n",
    "        sam_marg_cnt.append(sam_prop)\n",
    "        resam_marg_cnt.append(resam_prop)\n",
    "\n",
    "    sam_marg_cnt = np.concatenate(sam_marg_cnt) if sam_marg_cnt else np.array([])\n",
    "    resam_marg_cnt = np.concatenate(resam_marg_cnt) if resam_marg_cnt else np.array([])\n",
    "\n",
    "    if sam_marg_cnt.size > 0:\n",
    "        rmse_mar = np.linalg.norm(sam_marg_cnt - resam_marg_cnt) / np.sqrt(len(sam_marg_cnt))\n",
    "        ybar_mar = sam_marg_cnt.mean()\n",
    "        srmse_mar = rmse_mar / ybar_mar if ybar_mar != 0 else np.nan\n",
    "    else:\n",
    "        srmse_mar = np.nan\n",
    "\n",
    "    # ── Bivariate distribution ──────────────────────────────\n",
    "    bi_index = list(combinations(x_population.columns, 2))\n",
    "    sam_bi_cnt = []\n",
    "    resam_bi_cnt = []\n",
    "    for col1, col2 in bi_index:\n",
    "        pop_pair = x_population[[col1, col2]].dropna()\n",
    "        syn_pair = resamples[[col1, col2]].dropna()\n",
    "\n",
    "        sam = pd.DataFrame(pd.crosstab(pop_pair[col1], pop_pair[col2])).stack().sort_index()\n",
    "        resam = pd.DataFrame(pd.crosstab(syn_pair[col1], syn_pair[col2])).stack().sort_index()\n",
    "        sam.name = 'pop'\n",
    "        resam.name = 'syn'\n",
    "        tab = pd.merge(resam, sam, left_index=True, right_index=True, how='outer').fillna(0)\n",
    "        sam_prop = tab.iloc[:, 1].values / pop_pair.shape[0] if pop_pair.shape[0] > 0 else 0\n",
    "        resam_prop = tab.iloc[:, 0].values / syn_pair.shape[0] if syn_pair.shape[0] > 0 else 0\n",
    "        sam_bi_cnt.append(sam_prop)\n",
    "        resam_bi_cnt.append(resam_prop)\n",
    "\n",
    "    sam_bi_cnt = np.concatenate(sam_bi_cnt) if sam_bi_cnt else np.array([])\n",
    "    resam_bi_cnt = np.concatenate(resam_bi_cnt) if resam_bi_cnt else np.array([])\n",
    "\n",
    "    if sam_bi_cnt.size > 0:\n",
    "        rmse_bi = np.linalg.norm(sam_bi_cnt - resam_bi_cnt) / np.sqrt(len(sam_bi_cnt))\n",
    "        ybar_bi = sam_bi_cnt.mean()\n",
    "        srmse_bi = rmse_bi / ybar_bi if ybar_bi != 0 else np.nan\n",
    "    else:\n",
    "        srmse_bi = np.nan\n",
    "\n",
    "    return [srmse_mar, srmse_bi]\n",
    "\n",
    "\n",
    "def calculate_precision_recall(population_df, generated_df):\n",
    "    \"\"\"\n",
    "    Function to compute Precision and Recall\n",
    "    - Excludes rows containing any missing (NA) values across all columns\n",
    "    - Converts each row to a tuple for comparison\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    population_df : DataFrame\n",
    "        Original population DataFrame\n",
    "    generated_df : DataFrame\n",
    "        Generated synthetic population DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        precision, recall, F1 score, number of unique combinations, matching combination info\n",
    "    \"\"\"\n",
    "    all_cols = population_df.columns.tolist()\n",
    "\n",
    "    # Drop rows with any NA values (analysis copy)\n",
    "    p_pop_df = population_df.dropna(subset=all_cols)\n",
    "    p_gen_df = generated_df.dropna(subset=all_cols)\n",
    "\n",
    "    # Convert each row to a tuple\n",
    "    p_pop = p_pop_df[all_cols].apply(tuple, axis=1)\n",
    "    p_gen = p_gen_df[all_cols].apply(tuple, axis=1)\n",
    "\n",
    "    # Precision: proportion of generated profiles that appear in the population\n",
    "    pop_set = set(p_pop)\n",
    "    gen_in_pop = [1 if profile in pop_set else 0 for profile in p_gen]\n",
    "    precision = round(np.mean(gen_in_pop), 4)\n",
    "\n",
    "    # Recall: proportion of population profiles that appear in the generated data\n",
    "    gen_set = set(p_gen)\n",
    "    pop_in_gen = [1 if profile in gen_set else 0 for profile in p_pop]\n",
    "    recall = round(np.mean(pop_in_gen), 4)\n",
    "\n",
    "    # F1 score\n",
    "    f1_score = round(2 * (precision * recall) / (precision + recall), 4) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Intersect sets\n",
    "    matching_unique_combinations = pop_set.intersection(gen_set)\n",
    "\n",
    "    # Count matching rows in generated data\n",
    "    gen_value_counts = p_gen.value_counts()\n",
    "    matching_rows_count = sum(gen_value_counts[comb] for comb in matching_unique_combinations if comb in gen_value_counts)\n",
    "\n",
    "    unique_combinations = {\n",
    "        'population': int(p_pop.nunique()),\n",
    "        'generated': int(p_gen.nunique())\n",
    "    }\n",
    "\n",
    "    matching_combinations = {\n",
    "        'unique_types': len(matching_unique_combinations),\n",
    "        'total_count': matching_rows_count\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'unique_combinations': unique_combinations,\n",
    "        'matching_combinations': matching_combinations\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_synthetic_population(population_csv, generated_csv):\n",
    "    \"\"\"\n",
    "    Synthetic population evaluation function\n",
    "    - When reading CSV files, the string \"None\" is NOT treated as missing;\n",
    "      only empty strings ('') are considered NA.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    population_csv : str\n",
    "        File path to the original population CSV\n",
    "    generated_csv : str\n",
    "        File path to the generated synthetic population CSV\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {population_csv} and {generated_csv}...\")\n",
    "\n",
    "    population_df = pd.read_csv(population_csv, keep_default_na=False, na_values=[''])\n",
    "    generated_df = pd.read_csv(generated_csv, keep_default_na=False, na_values=[''])\n",
    "\n",
    "    # Check and align column names (and order)\n",
    "    if set(population_df.columns) != set(generated_df.columns):\n",
    "        print(\"Warning: Column names or order don't match between datasets\")\n",
    "        print(f\"Population columns: {population_df.columns.tolist()}\")\n",
    "        print(f\"Generated columns: {generated_df.columns.tolist()}\")\n",
    "        common_cols = list(set(population_df.columns) & set(generated_df.columns))\n",
    "        population_df = population_df[common_cols]\n",
    "        generated_df = generated_df[common_cols]\n",
    "        print(f\"Using common columns: {common_cols}\")\n",
    "\n",
    "    # Data summary\n",
    "    print(\"\\n=== Data Summary ===\")\n",
    "    print(f\"Population data: {len(population_df):,} rows, {len(population_df.columns)} columns\")\n",
    "    print(f\"Generated data: {len(generated_df):,} rows, {len(generated_df.columns)} columns\")\n",
    "\n",
    "    # SRMSE\n",
    "    print(\"\\nCalculating SRMSE...\")\n",
    "    srmse_results = SRMSE(population_df, generated_df)\n",
    "    print(f\"SRMSE for marginal distributions: {srmse_results[0]:.4f}\")\n",
    "    print(f\"SRMSE for bivariate distributions: {srmse_results[1]:.4f}\")\n",
    "\n",
    "    # Precision & Recall\n",
    "    print(\"\\nCalculating precision and recall...\")\n",
    "    pr_metrics = calculate_precision_recall(population_df, generated_df)\n",
    "\n",
    "    print(\"\\n=== Evaluation Metrics ===\")\n",
    "    print(f\"Precision: {pr_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {pr_metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {pr_metrics['f1_score']:.4f}\")\n",
    "\n",
    "    print(\"\\n=== Unique Combinations Analysis ===\")\n",
    "    print(f\"Population unique combinations: {pr_metrics['unique_combinations']['population']:,}\")\n",
    "    print(f\"Generated unique combinations: {pr_metrics['unique_combinations']['generated']:,}\")\n",
    "\n",
    "    print(\"\\n=== Matching Combinations Analysis ===\")\n",
    "    print(f\"Precision) Total rows in generated data: {len(generated_df):,}\")\n",
    "    print(f\"Precision) Rows matching the population: {pr_metrics['matching_combinations']['total_count']:,}\")\n",
    "    print(f\"Precision) Percentage of rows matching: {(pr_metrics['matching_combinations']['total_count']/len(generated_df)*100):.2f}%\")\n",
    "    print(f\"Recall   ) Total unique combinations in generated data: {pr_metrics['unique_combinations']['generated']:,}\")\n",
    "    print(f\"Recall   ) Unique combinations matching the population: {pr_metrics['matching_combinations']['unique_types']:,}\")\n",
    "    print(f\"Recall   ) Percentage of unique combinations matching: {(pr_metrics['matching_combinations']['unique_types']/pr_metrics['unique_combinations']['generated']*100):.2f}%\")\n",
    "\n",
    "    return {\n",
    "        'srmse_marginal': srmse_results[0],\n",
    "        'srmse_bivariate': srmse_results[1],\n",
    "        'precision': pr_metrics['precision'],\n",
    "        'recall': pr_metrics['recall'],\n",
    "        'f1_score': pr_metrics['f1_score'],\n",
    "        'unique_combinations': pr_metrics['unique_combinations'],\n",
    "        'matching_combinations': pr_metrics['matching_combinations']\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7705654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from h_population.csv and generated_synthetic_data_WGAN.csv...\n",
      "\n",
      "=== Data Summary ===\n",
      "Population data: 1,066,319 rows, 13 columns\n",
      "Generated data: 1,066,319 rows, 13 columns\n",
      "\n",
      "Calculating SRMSE...\n",
      "SRMSE for marginal distributions: 0.0319\n",
      "SRMSE for bivariate distributions: 0.0944\n",
      "\n",
      "Calculating precision and recall...\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "Precision: 0.8139\n",
      "Recall: 0.8079\n",
      "F1 Score: 0.8109\n",
      "\n",
      "=== Unique Combinations Analysis ===\n",
      "Population unique combinations: 264,005\n",
      "Generated unique combinations: 263,925\n",
      "\n",
      "=== Matching Combinations Analysis ===\n",
      "Precision) Total rows in generated data: 1,066,319\n",
      "Precision) Rows matching the population: 867,849\n",
      "Precision) Percentage of rows matching: 81.39%\n",
      "Recall   ) Total unique combinations in generated data: 263,925\n",
      "Recall   ) Unique combinations matching the population: 111,562\n",
      "Recall   ) Percentage of unique combinations matching: 42.27%\n"
     ]
    }
   ],
   "source": [
    "population_csv = \"h_population.csv\"\n",
    "subset_csv = \"generated_synthetic_data_WGAN.csv\"\n",
    "metrics = evaluate_synthetic_population(population_csv, subset_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf40b8-5f71-4623-a085-5b85e363462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from h_population.csv and generated_synthetic_data_VAE.csv...\n",
      "\n",
      "=== Data Summary ===\n",
      "Population data: 1,066,319 rows, 13 columns\n",
      "Generated data: 1,066,319 rows, 13 columns\n",
      "\n",
      "Calculating SRMSE...\n",
      "SRMSE for marginal distributions: 0.0366\n",
      "SRMSE for bivariate distributions: 0.0891\n",
      "\n",
      "Calculating precision and recall...\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "Precision: 0.7359\n",
      "Recall: 0.8147\n",
      "F1 Score: 0.7733\n",
      "\n",
      "=== Unique Combinations Analysis ===\n",
      "Population unique combinations: 264,005\n",
      "Generated unique combinations: 331,747\n",
      "\n",
      "=== Matching Combinations Analysis ===\n",
      "Precision) Total rows in generated data: 1,066,319\n",
      "Precision) Rows matching the population: 784,745\n",
      "Precision) Percentage of rows matching: 73.59%\n",
      "Recall   ) Total unique combinations in generated data: 331,747\n",
      "Recall   ) Unique combinations matching the population: 114,126\n",
      "Recall   ) Percentage of unique combinations matching: 34.40%\n"
     ]
    }
   ],
   "source": [
    "population_csv = \"h_population.csv\"\n",
    "subset_csv = \"generated_synthetic_data_VAE.csv\"\n",
    "metrics = evaluate_synthetic_population(population_csv, subset_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
