{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f36112-0d8a-4070-87ca-90dfcf286d16",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d8f71-d4ab-448d-9ec3-29b114039313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Local imports\n",
    "from utils.text_encoder import TextEncoder\n",
    "from Random_generator import RandomGenerator, TextDecoder\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfafde3-6c81-43c8-b1cf-0100e0691b3a",
   "metadata": {},
   "source": [
    "## Loading h_sample, h_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548f1ffa-ed2c-41d7-91b5-df11c51fcf75",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "h_sample = pd.read_csv('h_sample.csv')\n",
    "h_population = pd.read_csv('h_population.csv')\n",
    "print(\"Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c958d4d-098b-4017-ae25-84ce25dac6db",
   "metadata": {},
   "source": [
    "## Encoding h_sample with Random Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fafe2a0-89a2-45b9-904b-09ef6ffd9cdb",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding h_sample is completed.\n",
      "\n",
      " Test of 'Random Ordering' in first sample (profile):\n",
      "------------------------------\n",
      "Example1: \n",
      "\"Work days is 5 days, Home type is Apartment, Age group is [35,40), Major travel mode is Car, Number of household members is 4, Car ownership of household is Yes, Household monthly income level is 3M-5M KRW, Gender is Male, Education status is Not student, Kid in household is Yes, Work type is Simple labor, Driver license is Yes, Major departure time is Peak.\"\n",
      "------------------------------\n",
      "Example2: \n",
      "\"Kid in household is No, Household monthly income level is 1M-3M KRW, Driver license is Yes, Age group is [25,30), Major departure time is Peak, Work days is 5 days, Home type is Multi-family, Education status is Not student, Major travel mode is Public Transportation, Car ownership of household is No, Gender is Female, Work type is Manager/Office, Number of household members is 2.\"\n",
      "------------------------------\n",
      "Example3: \n",
      "\"Work days is Inoccupation/non-regular, Age group is [40,45), Car ownership of household is Yes, Gender is Female, Major travel mode is No commute, Major departure time is No commute, Education status is Not student, Household monthly income level is 5M-10M KRW, Home type is Apartment, Number of household members is 4, Kid in household is No, Driver license is Yes, Work type is Inoccupation/Housewife.\"\n",
      "------------------------------\n",
      "Example4: \n",
      "\"Work days is 5 days, Gender is Male, Home type is Apartment, Car ownership of household is Yes, Driver license is Yes, Work type is Other, Household monthly income level is 3M-5M KRW, Major travel mode is Public Transportation, Major departure time is Peak, Number of household members is 3, Age group is [60,65), Kid in household is No, Education status is Not student.\"\n",
      "------------------------------\n",
      "Example5: \n",
      "\"Age group is [45,50), Car ownership of household is Yes, Household monthly income level is 5M-10M KRW, Work type is Simple labor, Work days is 5 days, Number of household members is 5, Major departure time is Peak, Kid in household is Yes, Driver license is Yes, Gender is Male, Major travel mode is Car, Education status is Not student, Home type is Apartment.\"\n",
      "------------------------------\n",
      "Example6: \n",
      "\"Driver license is No, Major departure time is No commute, Car ownership of household is No, Education status is Not student, Household monthly income level is < 1M KRW, Number of household members is 1, Age group is [80,85), Work days is Inoccupation/non-regular, Home type is Single-family, Major travel mode is No commute, Work type is Service, Gender is Female, Kid in household is No.\"\n",
      "------------------------------\n",
      "Example7: \n",
      "\"Home type is Apartment, Number of household members is 4, Major travel mode is Walking, Major departure time is Peak, Gender is Female, Work days is Inoccupation/non-regular, Car ownership of household is Yes, Age group is [10,15), Work type is Student, Kid in household is No, Driver license is No, Education status is Elementary/Middle/High School, Household monthly income level is 5M-10M KRW.\"\n",
      "------------------------------\n",
      "Example8: \n",
      "\"Driver license is Yes, Work days is 1~4 days, Work type is Manager/Office, Major departure time is Peak, Household monthly income level is 5M-10M KRW, Kid in household is No, Car ownership of household is Yes, Education status is Not student, Major travel mode is Car, Number of household members is 4, Age group is [40,45), Home type is Apartment, Gender is Male.\"\n",
      "------------------------------\n",
      "Example9: \n",
      "\"Work type is Simple labor, Car ownership of household is Yes, Work days is 5 days, Gender is Male, Major departure time is Peak, Kid in household is Yes, Number of household members is 2, Age group is [30,35), Driver license is Yes, Household monthly income level is 5M-10M KRW, Major travel mode is Public Transportation, Education status is Not student, Home type is Apartment.\"\n",
      "------------------------------\n",
      "Example10: \n",
      "\"Work days is Inoccupation/non-regular, Car ownership of household is Yes, Kid in household is No, Gender is Female, Age group is [20,25), Work type is Student, Major travel mode is No commute, Household monthly income level is 3M-5M KRW, Number of household members is 4, Major departure time is No commute, Education status is University, Driver license is No, Home type is Single-family.\"\n"
     ]
    }
   ],
   "source": [
    "encoder = TextEncoder()\n",
    "\n",
    "# Encoding\n",
    "train_texts = encoder.encode_dataset(h_sample)\n",
    "\n",
    "print(\"Encoding h_sample is completed.\\n\\n Test of 'Random Ordering' in first sample (profile):\")\n",
    "for idx, text in enumerate(train_texts[:10], start=1):\n",
    "    print(\"------------------------------\")\n",
    "    print(f\"Example{idx}: \\n\\\"{text}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d23576-c50a-4671-8199-66b1966f3af8",
   "metadata": {},
   "source": [
    "## Make the LLM-Random model: Fine-tuning the GPT-2 with random ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd9b3d7-acd4-47c0-97cb-9209b73beaa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning the LLM-Random model\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.00:00<?, ?it/s]\n",
      "Epoch 1/40: 100%|████████████████████████| 6665/6665 [03:10<00:00, 35.03it/s, batch=6665/6665, loss=0.3264, tokens=294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/40\n",
      "Average Loss: 0.3634\n",
      "Epoch Time: 190.25s\n",
      "Tokens Processed: 5,123,734\n",
      "GPU Memory: 1080.16MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: 100%|████████████████████████| 6665/6665 [03:14<00:00, 34.33it/s, batch=6665/6665, loss=0.3600, tokens=276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/40\n",
      "Average Loss: 0.3411\n",
      "Epoch Time: 194.12s\n",
      "Tokens Processed: 5,123,444\n",
      "GPU Memory: 1079.27MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: 100%|████████████████████████| 6665/6665 [03:13<00:00, 34.48it/s, batch=6665/6665, loss=0.3438, tokens=279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/40\n",
      "Average Loss: 0.3388\n",
      "Epoch Time: 193.29s\n",
      "Tokens Processed: 5,120,927\n",
      "GPU Memory: 1077.57MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: 100%|████████████████████████| 6665/6665 [03:14<00:00, 34.21it/s, batch=6665/6665, loss=0.3254, tokens=291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/40\n",
      "Average Loss: 0.3374\n",
      "Epoch Time: 194.83s\n",
      "Tokens Processed: 5,122,915\n",
      "GPU Memory: 1078.93MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: 100%|████████████████████████| 6665/6665 [03:09<00:00, 35.20it/s, batch=6665/6665, loss=0.3004, tokens=291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/40\n",
      "Average Loss: 0.3366\n",
      "Epoch Time: 189.34s\n",
      "Tokens Processed: 5,124,451\n",
      "GPU Memory: 1080.62MB\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch5\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: 100%|████████████████████████| 6665/6665 [03:09<00:00, 35.18it/s, batch=6665/6665, loss=0.3287, tokens=282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/40\n",
      "Average Loss: 0.3360\n",
      "Epoch Time: 189.47s\n",
      "Tokens Processed: 5,123,458\n",
      "GPU Memory: 1077.89MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: 100%|████████████████████████| 6665/6665 [03:08<00:00, 35.41it/s, batch=6665/6665, loss=0.3597, tokens=288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/40\n",
      "Average Loss: 0.3357\n",
      "Epoch Time: 188.21s\n",
      "Tokens Processed: 5,122,512\n",
      "GPU Memory: 1080.69MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: 100%|████████████████████████| 6665/6665 [03:08<00:00, 35.32it/s, batch=6665/6665, loss=0.3166, tokens=291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/40\n",
      "Average Loss: 0.3352\n",
      "Epoch Time: 188.70s\n",
      "Tokens Processed: 5,124,371\n",
      "GPU Memory: 1081.99MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: 100%|████████████████████████| 6665/6665 [03:08<00:00, 35.40it/s, batch=6665/6665, loss=0.3342, tokens=288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/40\n",
      "Average Loss: 0.3351\n",
      "Epoch Time: 188.27s\n",
      "Tokens Processed: 5,122,552\n",
      "GPU Memory: 1081.13MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.30it/s, batch=6665/6665, loss=0.3301, tokens=279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/40\n",
      "Average Loss: 0.3349\n",
      "Epoch Time: 188.84s\n",
      "Tokens Processed: 5,123,151\n",
      "GPU Memory: 1078.32MB\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch10\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.38it/s, batch=6665/6665, loss=0.3338, tokens=291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/40\n",
      "Average Loss: 0.3347\n",
      "Epoch Time: 188.37s\n",
      "Tokens Processed: 5,123,587\n",
      "GPU Memory: 1082.04MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/40: 100%|███████████████████████| 6665/6665 [03:09<00:00, 35.14it/s, batch=6665/6665, loss=0.3512, tokens=282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/40\n",
      "Average Loss: 0.3344\n",
      "Epoch Time: 189.65s\n",
      "Tokens Processed: 5,124,482\n",
      "GPU Memory: 1077.52MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.32it/s, batch=6665/6665, loss=0.3283, tokens=297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/40\n",
      "Average Loss: 0.3343\n",
      "Epoch Time: 188.74s\n",
      "Tokens Processed: 5,123,497\n",
      "GPU Memory: 1082.50MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.37it/s, batch=6665/6665, loss=0.3294, tokens=282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/40\n",
      "Average Loss: 0.3341\n",
      "Epoch Time: 188.42s\n",
      "Tokens Processed: 5,124,578\n",
      "GPU Memory: 1081.56MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.28it/s, batch=6665/6665, loss=0.3431, tokens=276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/40\n",
      "Average Loss: 0.3342\n",
      "Epoch Time: 188.90s\n",
      "Tokens Processed: 5,122,036\n",
      "GPU Memory: 1075.29MB\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch15\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.42it/s, batch=6665/6665, loss=0.3203, tokens=291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/40\n",
      "Average Loss: 0.3339\n",
      "Epoch Time: 188.15s\n",
      "Tokens Processed: 5,124,035\n",
      "GPU Memory: 1081.00MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/40: 100%|███████████████████████| 6665/6665 [03:09<00:00, 35.18it/s, batch=6665/6665, loss=0.3455, tokens=285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/40\n",
      "Average Loss: 0.3339\n",
      "Epoch Time: 189.48s\n",
      "Tokens Processed: 5,122,837\n",
      "GPU Memory: 1081.09MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.43it/s, batch=6665/6665, loss=0.4044, tokens=267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/40\n",
      "Average Loss: 0.3338\n",
      "Epoch Time: 188.15s\n",
      "Tokens Processed: 5,122,971\n",
      "GPU Memory: 1075.68MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/40: 100%|███████████████████████| 6665/6665 [03:09<00:00, 35.26it/s, batch=6665/6665, loss=0.3267, tokens=291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/40\n",
      "Average Loss: 0.3335\n",
      "Epoch Time: 189.04s\n",
      "Tokens Processed: 5,125,011\n",
      "GPU Memory: 1080.68MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/40: 100%|███████████████████████| 6665/6665 [03:09<00:00, 35.19it/s, batch=6665/6665, loss=0.3499, tokens=279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/40\n",
      "Average Loss: 0.3336\n",
      "Epoch Time: 189.43s\n",
      "Tokens Processed: 5,123,255\n",
      "GPU Memory: 1078.76MB\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch20\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/40: 100%|███████████████████████| 6665/6665 [03:09<00:00, 35.20it/s, batch=6665/6665, loss=0.3287, tokens=285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/40\n",
      "Average Loss: 0.3335\n",
      "Epoch Time: 189.36s\n",
      "Tokens Processed: 5,124,629\n",
      "GPU Memory: 1077.97MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.39it/s, batch=6665/6665, loss=0.3198, tokens=297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/40\n",
      "Average Loss: 0.3333\n",
      "Epoch Time: 188.34s\n",
      "Tokens Processed: 5,125,433\n",
      "GPU Memory: 1082.86MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/40: 100%|███████████████████████| 6665/6665 [03:09<00:00, 35.12it/s, batch=6665/6665, loss=0.3180, tokens=288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/40\n",
      "Average Loss: 0.3333\n",
      "Epoch Time: 189.79s\n",
      "Tokens Processed: 5,123,984\n",
      "GPU Memory: 1079.33MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.34it/s, batch=6665/6665, loss=0.3350, tokens=294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/40\n",
      "Average Loss: 0.3334\n",
      "Epoch Time: 188.59s\n",
      "Tokens Processed: 5,122,318\n",
      "GPU Memory: 1082.41MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/40: 100%|███████████████████████| 6665/6665 [03:10<00:00, 34.96it/s, batch=6665/6665, loss=0.3224, tokens=282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/40\n",
      "Average Loss: 0.3333\n",
      "Epoch Time: 190.67s\n",
      "Tokens Processed: 5,123,250\n",
      "GPU Memory: 1078.51MB\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch25\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/40: 100%|███████████████████████| 6665/6665 [03:07<00:00, 35.62it/s, batch=6665/6665, loss=0.3160, tokens=282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/40\n",
      "Average Loss: 0.3332\n",
      "Epoch Time: 187.11s\n",
      "Tokens Processed: 5,122,986\n",
      "GPU Memory: 1077.94MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.43it/s, batch=6665/6665, loss=0.3248, tokens=282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/40\n",
      "Average Loss: 0.3331\n",
      "Epoch Time: 188.15s\n",
      "Tokens Processed: 5,124,210\n",
      "GPU Memory: 1076.70MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/40: 100%|███████████████████████| 6665/6665 [03:07<00:00, 35.60it/s, batch=6665/6665, loss=0.3655, tokens=279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/40\n",
      "Average Loss: 0.3331\n",
      "Epoch Time: 187.23s\n",
      "Tokens Processed: 5,124,431\n",
      "GPU Memory: 1080.52MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/40: 100%|███████████████████████| 6665/6665 [03:07<00:00, 35.49it/s, batch=6665/6665, loss=0.3831, tokens=273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/40\n",
      "Average Loss: 0.3332\n",
      "Epoch Time: 187.80s\n",
      "Tokens Processed: 5,122,265\n",
      "GPU Memory: 1076.13MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/40: 100%|███████████████████████| 6665/6665 [03:07<00:00, 35.49it/s, batch=6665/6665, loss=0.3360, tokens=291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/40\n",
      "Average Loss: 0.3330\n",
      "Epoch Time: 187.81s\n",
      "Tokens Processed: 5,122,819\n",
      "GPU Memory: 1082.67MB\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch30\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/40: 100%|███████████████████████| 6665/6665 [03:07<00:00, 35.47it/s, batch=6665/6665, loss=0.3465, tokens=264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/40\n",
      "Average Loss: 0.3329\n",
      "Epoch Time: 187.91s\n",
      "Tokens Processed: 5,123,104\n",
      "GPU Memory: 1074.60MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/40: 100%|███████████████████████| 6665/6665 [03:07<00:00, 35.63it/s, batch=6665/6665, loss=0.3214, tokens=291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/40\n",
      "Average Loss: 0.3328\n",
      "Epoch Time: 187.05s\n",
      "Tokens Processed: 5,124,243\n",
      "GPU Memory: 1082.50MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/40: 100%|███████████████████████| 6665/6665 [03:06<00:00, 35.69it/s, batch=6665/6665, loss=0.3157, tokens=291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/40\n",
      "Average Loss: 0.3328\n",
      "Epoch Time: 186.76s\n",
      "Tokens Processed: 5,123,955\n",
      "GPU Memory: 1080.48MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/40: 100%|███████████████████████| 6665/6665 [03:07<00:00, 35.61it/s, batch=6665/6665, loss=0.3983, tokens=273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/40\n",
      "Average Loss: 0.3327\n",
      "Epoch Time: 187.19s\n",
      "Tokens Processed: 5,124,393\n",
      "GPU Memory: 1077.77MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/40: 100%|███████████████████████| 6665/6665 [03:05<00:00, 35.86it/s, batch=6665/6665, loss=0.3210, tokens=294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/40\n",
      "Average Loss: 0.3326\n",
      "Epoch Time: 185.88s\n",
      "Tokens Processed: 5,124,886\n",
      "GPU Memory: 1081.36MB\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch35\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/40: 100%|███████████████████████| 6665/6665 [03:07<00:00, 35.47it/s, batch=6665/6665, loss=0.3668, tokens=279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/40\n",
      "Average Loss: 0.3327\n",
      "Epoch Time: 187.90s\n",
      "Tokens Processed: 5,123,935\n",
      "GPU Memory: 1081.04MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/40: 100%|███████████████████████| 6665/6665 [03:07<00:00, 35.57it/s, batch=6665/6665, loss=0.3309, tokens=288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/40\n",
      "Average Loss: 0.3327\n",
      "Epoch Time: 187.37s\n",
      "Tokens Processed: 5,123,432\n",
      "GPU Memory: 1080.70MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/40: 100%|███████████████████████| 6665/6665 [03:08<00:00, 35.36it/s, batch=6665/6665, loss=0.3353, tokens=282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/40\n",
      "Average Loss: 0.3326\n",
      "Epoch Time: 188.47s\n",
      "Tokens Processed: 5,123,410\n",
      "GPU Memory: 1080.18MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/40: 100%|███████████████████████| 6665/6665 [03:04<00:00, 36.05it/s, batch=6665/6665, loss=0.3418, tokens=282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/40\n",
      "Average Loss: 0.3325\n",
      "Epoch Time: 184.91s\n",
      "Tokens Processed: 5,123,962\n",
      "GPU Memory: 1077.29MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/40: 100%|███████████████████████| 6665/6665 [03:09<00:00, 35.25it/s, batch=6665/6665, loss=0.3305, tokens=282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/40\n",
      "Average Loss: 0.3325\n",
      "Epoch Time: 189.07s\n",
      "Tokens Processed: 5,122,466\n",
      "GPU Memory: 1078.28MB\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch40\n",
      "Model saved to saved_models/LLM-Random_distilgpt2_epoch40\n",
      "\n",
      "Training Complete!\n",
      "Total Training Time: 7554.89s\n",
      "Total Tokens Processed: 204,941,915\n",
      "Peak GPU Memory Usage: 2153.47MB\n",
      "\n",
      "Training metrics saved to Training Metrics\\training_metrics_20250505_163534.json\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "class DynamicTextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    For each **getitem** call, it dynamically encodes the corresponding row using TextEncoder.\n",
    "    Therefore, a different valid linear extension is applied each time.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, encoder):\n",
    "        self.dataframe = dataframe\n",
    "        self.encoder = encoder\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        return self.encoder.encode_row(row)\n",
    "\n",
    "# Creating DataLoader (using DynamicTextDataset for dynamic encoding)\n",
    "dynamic_dataset = DynamicTextDataset(h_sample, encoder)\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(dynamic_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# -------------------------------------------\n",
    "# Training\n",
    "# -------------------------------------------\n",
    "print(\"\\nFine-tuning the LLM-Random model\")\n",
    "generator = RandomGenerator(model_name='distilgpt2')  # gpt2-medium, gpt2-large\n",
    "learning_rate = 5e-5\n",
    "epochs = 40\n",
    "generator.init_optimizer(learning_rate=learning_rate)\n",
    "\n",
    "training_metrics = {\n",
    "    'epoch_losses': [],\n",
    "    'epoch_times': [],\n",
    "    'epoch_tokens': [],\n",
    "    'gpu_memory_usage': [],\n",
    "    'batch_metrics': []\n",
    "}\n",
    "\n",
    "results_dir = Path('Training Metrics')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "start_time = time.time()\n",
    "initial_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_metrics = {\n",
    "        'loss': 0,\n",
    "        'tokens': 0,\n",
    "        'batches': []\n",
    "    }\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        inputs = generator.tokenizer(\n",
    "            batch, \n",
    "            return_tensors='pt', \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=512\n",
    "        ).to(generator.device)\n",
    "        \n",
    "        outputs = generator.model(**inputs, labels=inputs['input_ids'])\n",
    "        loss = outputs.loss.item()\n",
    "        \n",
    "        generator.optimizer.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        generator.optimizer.step()\n",
    "        \n",
    "        batch_tokens = inputs['input_ids'].numel()\n",
    "        epoch_metrics['batches'].append({\n",
    "            'batch_idx': batch_idx,\n",
    "            'loss': loss,\n",
    "            'tokens': batch_tokens\n",
    "        })\n",
    "        epoch_metrics['tokens'] += batch_tokens\n",
    "        epoch_metrics['loss'] += loss\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'batch': f'{batch_idx+1}/{len(dataloader)}',\n",
    "            'loss': f'{loss:.4f}',\n",
    "            'tokens': batch_tokens\n",
    "        })\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    avg_loss = epoch_metrics['loss'] / len(dataloader)\n",
    "    \n",
    "    training_metrics['epoch_losses'].append(avg_loss)\n",
    "    training_metrics['epoch_times'].append(epoch_time)\n",
    "    training_metrics['epoch_tokens'].append(epoch_metrics['tokens'])\n",
    "    if torch.cuda.is_available():\n",
    "        current_memory = torch.cuda.memory_allocated()\n",
    "        training_metrics['gpu_memory_usage'].append((current_memory - initial_memory) / 1e6)\n",
    "    training_metrics['batch_metrics'].append(epoch_metrics)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Epoch Time: {epoch_time:.2f}s\")\n",
    "    print(f\"Tokens Processed: {epoch_metrics['tokens']:,}\")\n",
    "    if torch.cuda.is_available():\n",
    "        current_memory = torch.cuda.memory_allocated()\n",
    "        print(f\"GPU Memory: {(current_memory - initial_memory)/1e6:.2f}MB\")\n",
    "    \n",
    "    # Save model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        epoch_save_path = f\"saved_models/LLM-Random_distilgpt2_epoch{epoch+1}\"\n",
    "        generator.save_model(epoch_save_path)\n",
    "        print(f\"Model saved to {epoch_save_path}\")\n",
    "        \n",
    "training_metrics['total_time'] = time.time() - start_time\n",
    "training_metrics['total_tokens'] = sum(training_metrics['epoch_tokens'])\n",
    "training_metrics['peak_memory'] = (torch.cuda.max_memory_allocated() - initial_memory) / 1e6 if torch.cuda.is_available() else 0\n",
    "\n",
    "print(\"\\nTraining Complete!\")\n",
    "print(f\"Total Training Time: {training_metrics['total_time']:.2f}s\")\n",
    "print(f\"Total Tokens Processed: {training_metrics['total_tokens']:,}\")\n",
    "print(f\"Peak GPU Memory Usage: {training_metrics['peak_memory']:.2f}MB\")\n",
    "\n",
    "metrics_file = results_dir / f'training_metrics_{timestamp}.json'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(training_metrics, f, indent=2)\n",
    "print(f\"\\nTraining metrics saved to {metrics_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
