{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc71d70-85cc-4521-a03e-2f0a9503380b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Synthetic Population Generation Script =====\n",
      "Target: 5000 profiles\n",
      "Initial Batch Size: 200\n",
      "Few-shot Examples per Batch: 150\n",
      "Source CSV: h_sample-PE.csv\n",
      "Output Prefix: dynamic_population\n",
      "\n",
      "--- Loading source data from h_sample-PE.csv...\n",
      "Loaded 53315 rows from source data.\n",
      "\n",
      "--- Intermediate file not found (dynamic_population_intermediate_10102.json). Starting new generation. ---\n",
      "\n",
      "===== Generating Batch 1 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "Successfully parsed full JSON response (20 profiles).\n",
      "+++ Added 20 profiles. Total: 20/5000 (Remaining: 4980)\n",
      "\n",
      "===== Generating Batch 2 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 42529 (char 42528). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 235 profiles from incomplete JSON.\n",
      "+++ Added 235 profiles. Total: 255/5000 (Remaining: 4745)\n",
      "\n",
      "===== Generating Batch 3 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43562 (char 43561). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 233 profiles from incomplete JSON.\n",
      "+++ Added 233 profiles. Total: 488/5000 (Remaining: 4512)\n",
      "\n",
      "===== Generating Batch 4 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Expecting value: line 1 column 43589 (char 43588). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 236 profiles from incomplete JSON.\n",
      "+++ Added 236 profiles. Total: 724/5000 (Remaining: 4276)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_724.json\n",
      "\n",
      "===== Generating Batch 5 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43160 (char 43159). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 230 profiles from incomplete JSON.\n",
      "+++ Added 230 profiles. Total: 954/5000 (Remaining: 4046)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_954.json\n",
      "\n",
      "===== Generating Batch 6 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43554 (char 43553). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 232 profiles from incomplete JSON.\n",
      "+++ Added 232 profiles. Total: 1186/5000 (Remaining: 3814)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_1186.json\n",
      "\n",
      "===== Generating Batch 7 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43274 (char 43273). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 233 profiles from incomplete JSON.\n",
      "+++ Added 233 profiles. Total: 1419/5000 (Remaining: 3581)\n",
      "\n",
      "===== Generating Batch 8 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Expecting ',' delimiter: line 1 column 43214 (char 43213). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 230 profiles from incomplete JSON.\n",
      "+++ Added 230 profiles. Total: 1649/5000 (Remaining: 3351)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_1649.json\n",
      "\n",
      "===== Generating Batch 9 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "Successfully parsed full JSON response (211 profiles).\n",
      "+++ Added 211 profiles. Total: 1860/5000 (Remaining: 3140)\n",
      "\n",
      "===== Generating Batch 10 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Expecting value: line 1 column 43477 (char 43476). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 236 profiles from incomplete JSON.\n",
      "+++ Added 236 profiles. Total: 2096/5000 (Remaining: 2904)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_2096.json\n",
      "\n",
      "===== Generating Batch 11 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Expecting value: line 1 column 43973 (char 43972). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 234 profiles from incomplete JSON.\n",
      "+++ Added 234 profiles. Total: 2330/5000 (Remaining: 2670)\n",
      "\n",
      "===== Generating Batch 12 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43275 (char 43274). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 231 profiles from incomplete JSON.\n",
      "+++ Added 231 profiles. Total: 2561/5000 (Remaining: 2439)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_2561.json\n",
      "\n",
      "===== Generating Batch 13 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43522 (char 43521). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 228 profiles from incomplete JSON.\n",
      "+++ Added 228 profiles. Total: 2789/5000 (Remaining: 2211)\n",
      "\n",
      "===== Generating Batch 14 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43123 (char 43122). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 231 profiles from incomplete JSON.\n",
      "+++ Added 231 profiles. Total: 3020/5000 (Remaining: 1980)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_3020.json\n",
      "\n",
      "===== Generating Batch 15 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43055 (char 43054). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 232 profiles from incomplete JSON.\n",
      "+++ Added 232 profiles. Total: 3252/5000 (Remaining: 1748)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_3252.json\n",
      "\n",
      "===== Generating Batch 16 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "Successfully parsed full JSON response (20 profiles).\n",
      "+++ Added 20 profiles. Total: 3272/5000 (Remaining: 1728)\n",
      "\n",
      "===== Generating Batch 17 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "Successfully parsed full JSON response (142 profiles).\n",
      "+++ Added 142 profiles. Total: 3414/5000 (Remaining: 1586)\n",
      "\n",
      "===== Generating Batch 18 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "Successfully parsed full JSON response (20 profiles).\n",
      "+++ Added 20 profiles. Total: 3434/5000 (Remaining: 1566)\n",
      "\n",
      "===== Generating Batch 19 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43757 (char 43756). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 235 profiles from incomplete JSON.\n",
      "+++ Added 235 profiles. Total: 3669/5000 (Remaining: 1331)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_3669.json\n",
      "\n",
      "===== Generating Batch 20 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43365 (char 43364). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 236 profiles from incomplete JSON.\n",
      "+++ Added 236 profiles. Total: 3905/5000 (Remaining: 1095)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_3905.json\n",
      "\n",
      "===== Generating Batch 21 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43634 (char 43633). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 232 profiles from incomplete JSON.\n",
      "+++ Added 232 profiles. Total: 4137/5000 (Remaining: 863)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_4137.json\n",
      "\n",
      "===== Generating Batch 22 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43390 (char 43389). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 234 profiles from incomplete JSON.\n",
      "+++ Added 234 profiles. Total: 4371/5000 (Remaining: 629)\n",
      "\n",
      "===== Generating Batch 23 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43788 (char 43787). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 231 profiles from incomplete JSON.\n",
      "+++ Added 231 profiles. Total: 4602/5000 (Remaining: 398)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_4602.json\n",
      "\n",
      "===== Generating Batch 24 =====\n",
      "Target for this batch: 200 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 200 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43164 (char 43163). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 229 profiles from incomplete JSON.\n",
      "+++ Added 229 profiles. Total: 4831/5000 (Remaining: 169)\n",
      "\n",
      "===== Generating Batch 25 =====\n",
      "Target for this batch: 169 profiles (using 150 examples)\n",
      "--- Generating 150 dynamic few-shot examples for this batch...\n",
      ">>> Calling OpenAI API (requesting 169 profiles)...\n",
      "<<< OpenAI API call finished.\n",
      "--- Failed to parse full JSON: Unterminated string starting at: line 1 column 43891 (char 43890). Attempting to salvage profiles...\n",
      "--- Successfully salvaged 233 profiles from incomplete JSON.\n",
      "+++ Added 233 profiles. Total: 5064/5000 (Remaining: -64)\n",
      "--- Saved intermediate result to dynamic_population_intermediate_5064.json\n",
      "\n",
      "===== Generation Loop Finished =====\n",
      "\n",
      "==== Generation Complete. Achieved target of 5000 (generated 5064). ====\n",
      "--- Note: Generated 5064 profiles, trimming to target 5000.\n",
      "\n",
      "--- Saving final 5000 profiles ---\n",
      "Saved JSON to dynamic_population_final_5000.json\n",
      "Saved CSV to dynamic_population_final_5000.csv\n",
      "===== Script Finished =====\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random # Added for random sampling if needed, though pandas.sample handles it\n",
    "\n",
    "# --------------------\n",
    "# 0) Configuration & Constants\n",
    "# --------------------\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY_POPSYNTH')\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Please set the environment variable OPENAI_API_KEY_POPSYNTH\")\n",
    "openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Define the path to your source CSV file\n",
    "SOURCE_CSV_PATH = \"data/h_sample-PE.csv\"\n",
    "\n",
    "# --- Mapping Dictionaries ---\n",
    "GENDER_MAP = {1: \"Male\", 2: \"Female\"}\n",
    "HOMEINCOME_MAP = {\n",
    "    1: \"less than 1 million Won\",\n",
    "    2: \"between 1 million Won and 3 million Won\",\n",
    "    3: \"between 3 million Won and 5 million Won\",\n",
    "    4: \"between 5 million Won and 10 million Won\",\n",
    "    5: \"more than 10 million Won\",\n",
    "}\n",
    "HOMETYPE_MAP = {\n",
    "    1: \"Apartment\", 2: \"Villa\", 3: \"Multi-family house\",\n",
    "    4: \"Single-family house\", 5: \"Studio-type residence\", 6: \"Other\"\n",
    "}\n",
    "CAROWN_MAP = {1: \"Yes\", 2: \"No\"}\n",
    "DRIVER_MAP = {1: \"Yes\", 2: \"No\"}\n",
    "WORKDAYS_MAP = {\n",
    "    1: \"5 days\", 2: \"6 days\", 3: \"1-4 days\", 4: \"Inoccupation/non-regular\"\n",
    "}\n",
    "WORKTYPE_MAP = {\n",
    "    1: \"Student\", 2: \"Inoccupation/Housewife\", 3: \"Experts\", 4: \"Service\",\n",
    "    5: \"Sales\", 6: \"Manager/Office\", 7: \"Agriculture and fisher\",\n",
    "    8: \"Simple labor\", 9: \"Others\"\n",
    "}\n",
    "STUDENT_MAP = {\n",
    "    1: \"Elementary/Middle/High School\", 2: \"Pre-school Child\",\n",
    "    3: \"University\", 4: \"Not a Student\"\n",
    "}\n",
    "KIDINHH_MAP = {1: \"Yes\", 2: \"No\"}\n",
    "COMMODE_MAP = {\n",
    "    \"Car\": \"Car\", \"Public Transportation\": \"Public Transportation\",\n",
    "    \"None(did not travel)\": \"None(did not travel)\", \"Walking\": \"Walking\",\n",
    "    \"Bike/Bicycle\": \"Bike/Bicycle\", \"Taxi\": \"Taxi\"\n",
    "}\n",
    "COMTIME_MAP = {\n",
    "    \"Peak\": \"Peak (05:00–8:00)\", \"Non-Peak\": \"Non-Peak (09:00–12:00)\",\n",
    "    \"Other\": \"Other than peak/non-peak\", \"None(did not travel)\": \"None(did not travel)\"\n",
    "}\n",
    "\n",
    "# Expected columns in the CSV - adjust if your CSV has different names\n",
    "EXPECTED_COLUMNS = [\n",
    "    \"Age\", \"Gender\", \"Homeincome\", \"Hometype\", \"CarOwn\", \"Driver\",\n",
    "    \"Workdays\", \"Worktype\", \"Student\", \"NumHH\", \"KidinHH\", \"ComMode\", \"ComTime\"\n",
    "]\n",
    "\n",
    "# --------------------\n",
    "# 1) Function Schema Definition\n",
    "# --------------------\n",
    "FUNCTION_SCHEMA = {\n",
    "    \"name\": \"generate_synthetic_population\",\n",
    "    \"description\": \"Generates synthetic population profiles of South Korea following codebook definitions\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\"profiles\"],\n",
    "        \"properties\": {\n",
    "            \"profiles\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"required\": [\n",
    "                        \"Gender\", \"Age\", \"Homeincome\", \"Hometype\",\n",
    "                        \"CarOwn\", \"Driver\", \"Workdays\", \"Worktype\",\n",
    "                        \"Student\", \"NumHH\", \"KidinHH\", \"ComMode\", \"ComTime\"\n",
    "                    ],\n",
    "                    \"properties\": {\n",
    "                        \"Gender\": {\"type\": \"integer\", \"enum\": [1, 2], \"description\": \"1: Male, 2: Female\"},\n",
    "                        \"Age\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"pattern\": \"^(?:\\\\[\\\\d+,\\\\d+\\\\)|\\\\[85,90\\\\])$\",\n",
    "                            \"description\": \"Reported `Age Group` [start,end) format, 5-year increments. Final range [85,90].\"\n",
    "                        },\n",
    "                        \"Homeincome\": {\"type\": \"integer\", \"enum\": [1, 2, 3, 4, 5], \"description\": \"Household monthly Income level (KRW). 1: <1M, 2: 1-3M, 3: 3-5M, 4: 5-10M, 5: >10M\"},\n",
    "                        \"Hometype\": {\"type\": \"integer\", \"enum\": [1, 2, 3, 4, 5, 6], \"description\": \"Home Type. 1: Apt, 2: Villa, 3: Multi-family, 4: Single-family, 5: Studio, 6: Other\"},\n",
    "                        \"CarOwn\": {\"type\": \"integer\", \"enum\": [1, 2], \"description\": \"Household Car Ownership: 1: Yes, 2: No\"},\n",
    "                        \"Driver\": {\"type\": \"integer\", \"enum\": [1, 2], \"description\": \"Has Driver License: 1: Yes, 2: No\"},\n",
    "                        \"Workdays\": {\"type\": \"integer\", \"enum\": [1, 2, 3, 4], \"description\": \"Working Days/week. 1: 5days, 2: 6days, 3: 1-4days, 4: Inoccupation/non-regular\"},\n",
    "                        \"Worktype\": {\"type\": \"integer\", \"enum\": [1, 2, 3, 4, 5, 6, 7, 8, 9], \"description\": \"Working Type. 1: Student, 2: Inoccupation/Housewife, 3: Experts, 4: Service, 5: Sales, 6: Manager/Office, 7: Agri/fisher, 8: Simple labor, 9: Others\"},\n",
    "                        \"Student\": {\"type\": \"integer\", \"enum\": [1, 2, 3, 4], \"description\": \"Education Status. 1: Elem/Mid/High, 2: Pre-school, 3: University, 4: Not Student\"},\n",
    "                        \"NumHH\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 7, \"description\": \"Number of Household Members (1–7)\"},\n",
    "                        \"KidinHH\": {\"type\": \"integer\", \"enum\": [1, 2], \"description\": \"Presence of Kid in Household: 1: Yes, 2: No\"},\n",
    "                        \"ComMode\": {\"type\": \"string\", \"enum\": [\"Car\", \"Public Transportation\", \"None(did not travel)\", \"Walking\", \"Bike/Bicycle\", \"Taxi\"], \"description\": \"Major Travel Mode for 'Regular Travel' (commute, school, etc.)\"},\n",
    "                        \"ComTime\": {\"type\": \"string\", \"enum\": [\"Peak\", \"Non-Peak\", \"Other\", \"None(did not travel)\"], \"description\": \"Major Departure Time for 'Regular Travel'. Peak(5-8), Non-Peak(9-12), Other, None.\"}\n",
    "                    },\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "# --------------------\n",
    "# 2) Helper Functions for Few-Shot Example Generation\n",
    "# --------------------\n",
    "def convert_row_to_sentence(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Converts a DataFrame row (representing one person) into a descriptive sentence\n",
    "    using the predefined mapping dictionaries. Handles potential errors during mapping.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to map each field, using .get() for safety or direct access with try-except\n",
    "        age_str = str(row[\"Age\"]) # Age is usually a string already '[X,Y)'\n",
    "        gender_str = GENDER_MAP.get(int(row[\"Gender\"]), \"Unknown Gender\")\n",
    "        homeincome_str = HOMEINCOME_MAP.get(int(row[\"Homeincome\"]), \"Unknown Income\")\n",
    "        hometype_str = HOMETYPE_MAP.get(int(row[\"Hometype\"]), \"Unknown Home Type\")\n",
    "        carown_str = CAROWN_MAP.get(int(row[\"CarOwn\"]), \"Unknown Car Ownership\")\n",
    "        driver_str = DRIVER_MAP.get(int(row[\"Driver\"]), \"Unknown Driver Status\")\n",
    "        workdays_str = WORKDAYS_MAP.get(int(row[\"Workdays\"]), \"Unknown Workdays\")\n",
    "        worktype_str = WORKTYPE_MAP.get(int(row[\"Worktype\"]), \"Unknown Worktype\")\n",
    "        student_str = STUDENT_MAP.get(int(row[\"Student\"]), \"Unknown Student Status\")\n",
    "        numhh_str = str(row[\"NumHH\"])\n",
    "        kidinhh_str = KIDINHH_MAP.get(int(row[\"KidinHH\"]), \"Unknown Kid Status\")\n",
    "        commode_str = COMMODE_MAP.get(str(row[\"ComMode\"]), \"Unknown Commute Mode\") # Ensure ComMode is string\n",
    "        comtime_str = COMTIME_MAP.get(str(row[\"ComTime\"]), \"Unknown Commute Time\") # Ensure ComTime is string\n",
    "\n",
    "        sentence = (\n",
    "            f\"Gender is {gender_str}, \"\n",
    "            f\"The Respondent's Reported Age Group is {age_str}, \"\n",
    "            f\"Education enrollment status is {student_str}, \"\n",
    "            f\"Working Type is {worktype_str}, \"\n",
    "            f\"Usual Working Days per week is {workdays_str}, \"\n",
    "            f\"Driver License status is {driver_str}, \\n\"\n",
    "            f\"Monthly Household Income is {homeincome_str}, \"\n",
    "            f\"The number of Household Members is {numhh_str}, \"\n",
    "            f\"The presence of a Kid in the Household is {kidinhh_str}, \"\n",
    "            f\"Home Type is {hometype_str}, \"\n",
    "            f\"The Household Car Ownership is {carown_str}, \\n\"\n",
    "            f\"Major Travel Mode of the Respondent's Regular Travel is {commode_str}, \"\n",
    "            f\"Major Departure Time of the Respondent's Regular Travel is {comtime_str}.\"\n",
    "        )\n",
    "        return sentence\n",
    "    except (KeyError, ValueError, TypeError) as e:\n",
    "        print(f\"--- Warning: Error converting row to sentence: {e}. Row data: {row.to_dict()}\")\n",
    "        # Return a placeholder or skip this row in the calling function\n",
    "        return f\"Error processing example: {e}\"\n",
    "\n",
    "\n",
    "def generate_dynamic_few_shot_examples(source_df: pd.DataFrame, num_examples: int) -> str:\n",
    "    \"\"\"\n",
    "    Randomly samples rows from the source DataFrame, converts them to sentences,\n",
    "    and formats them as a string for the API prompt.\n",
    "    \"\"\"\n",
    "    if num_examples <= 0:\n",
    "        return \"\"\n",
    "    if num_examples > len(source_df):\n",
    "         print(f\"--- Warning: Requested {num_examples} examples, but only {len(source_df)} available in source data. Using all available.\")\n",
    "         num_examples = len(source_df)\n",
    "\n",
    "    # Randomly sample WITHOUT a fixed random_state for variability\n",
    "    sampled_df = source_df.sample(n=num_examples) # No random_state\n",
    "\n",
    "    example_texts = []\n",
    "    for i, (_, row) in enumerate(sampled_df.iterrows(), 1):\n",
    "        sentence = convert_row_to_sentence(row)\n",
    "        # Only include successfully converted sentences\n",
    "        if not sentence.startswith(\"Error processing example\"):\n",
    "             # Using \"Example\" consistently now, but kept original format just in case\n",
    "            example_texts.append(f\"-----\\nExample {i}:\\n{sentence}\")\n",
    "\n",
    "    return '\\n'.join(example_texts)\n",
    "\n",
    "# --------------------\n",
    "# 3) JSON Salvaging Function\n",
    "# --------------------\n",
    "def salvage_profiles_from_incomplete_json(arguments_str):\n",
    "    \"\"\"\n",
    "    Attempts to extract complete profile JSON objects from a potentially incomplete JSON string.\n",
    "    \"\"\"\n",
    "    profiles = []\n",
    "    processed_str = arguments_str\n",
    "\n",
    "    # Basic preprocessing: Find the start of the profiles array\n",
    "    try:\n",
    "        start_idx = processed_str.find('\"profiles\":[')\n",
    "        if start_idx >= 0:\n",
    "            start_idx += len('\"profiles\":[')\n",
    "            processed_str = processed_str[start_idx:]\n",
    "            first_brace = processed_str.find('{')\n",
    "            if first_brace >= 0:\n",
    "                processed_str = processed_str[first_brace:]\n",
    "            else:\n",
    "                 print(\"Salvage Preprocessing: No starting '{' found after '\\\"profiles\\\":['.\")\n",
    "                 processed_str = \"\"\n",
    "        else:\n",
    "             # If \"profiles\" key isn't found, maybe the structure is different?\n",
    "             # For now, assume it starts with { if it's just one profile, or [{ if multiple\n",
    "             processed_str = processed_str.strip()\n",
    "             if processed_str.startswith('['):\n",
    "                 first_brace = processed_str.find('{')\n",
    "                 if first_brace >= 0:\n",
    "                      processed_str = processed_str[first_brace:]\n",
    "                 else: processed_str = \"\"\n",
    "             elif not processed_str.startswith('{'):\n",
    "                 print(\"Salvage Preprocessing: String doesn't start with expected JSON object/array structure.\")\n",
    "                 processed_str = \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Salvage Preprocessing Error: {e}\")\n",
    "        processed_str = \"\"\n",
    "\n",
    "    # Manual extraction based on balanced braces\n",
    "    if processed_str:\n",
    "        try:\n",
    "            idx = 0\n",
    "            while idx < len(processed_str):\n",
    "                if processed_str[idx] == '{':\n",
    "                    start = idx\n",
    "                    brace_count = 1\n",
    "                    idx += 1\n",
    "                    # Find matching closing brace\n",
    "                    while idx < len(processed_str) and brace_count > 0:\n",
    "                        if processed_str[idx] == '{':\n",
    "                            brace_count += 1\n",
    "                        elif processed_str[idx] == '}':\n",
    "                            brace_count -= 1\n",
    "                        idx += 1\n",
    "\n",
    "                    # If braces match, try parsing this segment\n",
    "                    if brace_count == 0:\n",
    "                        profile_str = processed_str[start:idx]\n",
    "                        try:\n",
    "                            profile = json.loads(profile_str)\n",
    "                            # Validate required fields (using the list defined earlier)\n",
    "                            if all(field in profile for field in FUNCTION_SCHEMA[\"parameters\"][\"properties\"][\"profiles\"][\"items\"][\"required\"]):\n",
    "                                profiles.append(profile)\n",
    "                            # else:\n",
    "                            #     print(f\"Salvaged object skipped (missing required fields): {profile_str[:100]}...\") # Debugging\n",
    "                        except json.JSONDecodeError:\n",
    "                            # print(f\"Salvaged object skipped (JSONDecodeError): {profile_str[:100]}...\") # Debugging\n",
    "                            pass # Skip malformed JSON segments\n",
    "                    else:\n",
    "                        # Incomplete object found at the end\n",
    "                        # print(f\"Salvage stopped: Incomplete JSON object found starting at index {start}.\") # Debugging\n",
    "                        break # Stop processing\n",
    "                else:\n",
    "                    idx += 1 # Move to the next character if not starting brace\n",
    "        except Exception as e:\n",
    "            print(f\"Manual object extraction error during salvage: {e}\")\n",
    "\n",
    "    # print(f\"Salvage attempt result: Found {len(profiles)} potentially complete profiles.\") # Debugging\n",
    "    return profiles\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# 4) Synthetic Population API Call Function\n",
    "# --------------------\n",
    "def call_gpt_function_call_batch(batch_size: int, source_df: pd.DataFrame, num_examples_to_generate: int):\n",
    "    \"\"\"\n",
    "    Generates dynamic few-shot examples and calls the GPT-4 function calling API\n",
    "    to create a batch of synthetic population profiles.\n",
    "\n",
    "    Args:\n",
    "        batch_size: Number of profiles to request in this batch.\n",
    "        source_df: DataFrame containing the source data for sampling examples.\n",
    "        num_examples_to_generate: How many few-shot examples to sample and generate.\n",
    "    \"\"\"\n",
    "\n",
    "    # ** Dynamically generate few-shot examples for this specific call **\n",
    "    print(f\"--- Generating {num_examples_to_generate} dynamic few-shot examples for this batch...\")\n",
    "    few_shot_examples = generate_dynamic_few_shot_examples(source_df, num_examples_to_generate)\n",
    "    if not few_shot_examples:\n",
    "        print(\"--- Warning: No few-shot examples generated. Proceeding without them.\")\n",
    "\n",
    "    # Construct the system message using the dynamically generated examples\n",
    "    system_message_content = f\"\"\"\n",
    "# Your Role:\n",
    "You are an experienced demographic data scientist specialized in generating synthetic population data representative of South Korean demographics.\n",
    "\n",
    "# Your mission:\n",
    "- Produce a JSON function call to the function \"generate_synthetic_population\", providing realistic synthetic population profiles that reflect typical demographic characteristics of South Korea.\n",
    "- Each profile must strictly adhere to the codebook constraints described below, without omitting any required fields.\n",
    "\n",
    "# Function: generate_synthetic_population\n",
    "- Parameter:\n",
    "    \"profiles\": an array of objects, each describing one person's Socio-Demographic and Travel-Related attributes\n",
    "- Each object must include these properties (strictly follow data types and enums/patterns):\n",
    "    ## Socio-Demographic attributes - Individual Level\n",
    "    1) Gender (integer enum: 1=Male, 2=Female)\n",
    "    2) Age (string pattern: \"[start,end)\" – using 5-year increments, last group \"[85,90]\")\n",
    "    3) Student (integer enum: 1-4)\n",
    "    4) Worktype (integer enum: 1-9)\n",
    "    5) Workdays (integer enum: 1-4)\n",
    "    6) Driver (integer enum: 1=Yes, 2=No)\n",
    "\n",
    "    ## Socio-Demographic attributes - Household Level\n",
    "    7) Homeincome (integer enum: 1-5)\n",
    "    8) NumHH (integer range: 1-7)\n",
    "    9) KidinHH (integer enum: 1=Yes, 2=No)\n",
    "    10) Hometype (integer enum: 1-6)\n",
    "    11) CarOwn (integer enum: 1=Yes, 2=No)\n",
    "\n",
    "    ## Travel-Related attributes\n",
    "    12) ComMode (string enum: \"Car\", \"Public Transportation\", \"None(did not travel)\", \"Walking\", \"Bike/Bicycle\", \"Taxi\")\n",
    "    13) ComTime (string enum: \"Peak\", \"Non-Peak\", \"Other\", \"None(did not travel)\")\n",
    "\n",
    "# Please carefully follow these rules:\n",
    "- Do not add extra fields outside the required ones.\n",
    "- Ensure values strictly match their defined enums, data types, and patterns.\n",
    "- Firstly, Analyze the provided Few-shot Examples to capture characteristics of the Korean population regarding:\n",
    "    (1) \"Demographic Consistency\", (2) \"Household Structure Consistency\", (3) \"Work Situation Realism\", and (4) \"Travel Behavior Plausibility\"\n",
    "- Then, generate each profile's JSON, ensuring it is not only **feasible** according to the schema but also **realistic and varied**, reflecting the patterns observed in the examples.\n",
    "- Think carefully and logically to generate population, referring to the few-shot examples.\n",
    "\n",
    "# Few-shot Examples:\n",
    "- These {num_examples_to_generate} examples are sampled from actual survey data (South Korean HTS).\n",
    "- Use these examples primarily to learn realistic correlations and distributions for the generation, guided by the four perspectives.\n",
    "\n",
    "<few_shot_examples>\n",
    "{few_shot_examples}\n",
    "</few_shot_examples>\n",
    "    \"\"\"\n",
    "\n",
    "    system_message = {\"role\": \"system\", \"content\": system_message_content}\n",
    "    user_message = {\"role\": \"user\", \"content\": f\"Generate {batch_size} synthetic profiles.\"}\n",
    "\n",
    "    # API Call\n",
    "    try:\n",
    "        print(f\">>> Calling OpenAI API (requesting {batch_size} profiles)...\")\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\", # Or your preferred model\n",
    "            messages=[system_message, user_message],\n",
    "            temperature=0.3, # Slightly increased temperature for more variety based on examples\n",
    "            tools=[{\"type\": \"function\", \"function\": FUNCTION_SCHEMA}],\n",
    "            tool_choice={\"type\": \"function\", \"function\": {\"name\": \"generate_synthetic_population\"}},\n",
    "            # Consider adding a timeout (e.g., timeout=180 for 3 minutes)\n",
    "        )\n",
    "        print(\"<<< OpenAI API call finished.\")\n",
    "    except Exception as api_error:\n",
    "        print(f\"!!! OpenAI API call failed: {api_error}\")\n",
    "        return None # API call itself failed\n",
    "\n",
    "    # Response Processing\n",
    "    if not response or not response.choices:\n",
    "        print(\"!!! Received invalid or empty response from API.\")\n",
    "        return None\n",
    "\n",
    "    message = response.choices[0].message\n",
    "    tool_calls = message.tool_calls\n",
    "\n",
    "    if tool_calls:\n",
    "        tool_call = tool_calls[0] # Assume only one tool call as requested\n",
    "        if tool_call.function.name == \"generate_synthetic_population\":\n",
    "            raw_arguments = tool_call.function.arguments\n",
    "            try:\n",
    "                # Attempt to parse the full JSON\n",
    "                parsed_args = json.loads(raw_arguments)\n",
    "                num_parsed = len(parsed_args.get('profiles', []))\n",
    "                print(f\"Successfully parsed full JSON response ({num_parsed} profiles).\")\n",
    "                # Basic validation: Check if 'profiles' key exists and is a list\n",
    "                if 'profiles' in parsed_args and isinstance(parsed_args['profiles'], list):\n",
    "                     return parsed_args\n",
    "                else:\n",
    "                     print(\"!!! Parsed JSON is missing 'profiles' list. Attempting salvage.\")\n",
    "                     # Fall through to salvage attempt\n",
    "                     raise json.JSONDecodeError(\"Missing 'profiles' list\", raw_arguments, 0)\n",
    "\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"--- Failed to parse full JSON: {e}. Attempting to salvage profiles...\")\n",
    "                salvaged_profiles = salvage_profiles_from_incomplete_json(raw_arguments)\n",
    "\n",
    "                if salvaged_profiles:\n",
    "                    print(f\"--- Successfully salvaged {len(salvaged_profiles)} profiles from incomplete JSON.\")\n",
    "                    return {\"profiles\": salvaged_profiles}\n",
    "                else:\n",
    "                    print(\"--- Salvage attempt failed or found no complete profiles.\")\n",
    "                    return None # Salvage failed\n",
    "            except Exception as other_e: # Catch other potential errors during processing\n",
    "                print(f\"!!! Error processing function call arguments: {other_e}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"!!! API returned unexpected function call: {tool_call.function.name}\")\n",
    "            return None # Wrong function called\n",
    "    elif message.content:\n",
    "        print(f\"!!! API returned text content instead of function call: {message.content[:200]}...\")\n",
    "        return None # API didn't use the function\n",
    "    else:\n",
    "        print(\"!!! No tool calls or content found in the API response.\")\n",
    "        return None # Empty/unrecognized response\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# 5) Batch Processing Loop\n",
    "# --------------------\n",
    "def generate_large_population(total_profiles: int, batch_size: int, source_df: pd.DataFrame, num_examples_per_batch: int, output_prefix: str):\n",
    "    \"\"\"\n",
    "    Generates a large number of population profiles in batches, saving intermediate results.\n",
    "\n",
    "    Args:\n",
    "        total_profiles: Total number of profiles to generate.\n",
    "        batch_size: Max profiles to request per API call.\n",
    "        source_df: DataFrame with source data for generating few-shot examples.\n",
    "        num_examples_per_batch: Number of few-shot examples to generate for each batch.\n",
    "        output_prefix: Prefix for saving intermediate and final files (e.g., \"generated_population\").\n",
    "    \"\"\"\n",
    "    all_profiles = {\"profiles\": []}\n",
    "    remaining = total_profiles\n",
    "    batch_count = 0\n",
    "    current_batch_size_tracker = batch_size # Tracks adaptive batch size\n",
    "\n",
    "    while remaining > 0:\n",
    "        batch_count += 1\n",
    "        current_batch_size = min(current_batch_size_tracker, remaining)\n",
    "\n",
    "        print(f\"\\n===== Generating Batch {batch_count} =====\")\n",
    "        print(f\"Target for this batch: {current_batch_size} profiles (using {num_examples_per_batch} examples)\")\n",
    "\n",
    "        # Call API for the batch, passing the source DataFrame\n",
    "        result = call_gpt_function_call_batch(current_batch_size, source_df, num_examples_per_batch)\n",
    "\n",
    "        if result and \"profiles\" in result and isinstance(result[\"profiles\"], list):\n",
    "            generated_count = len(result[\"profiles\"])\n",
    "            if generated_count > 0:\n",
    "                all_profiles[\"profiles\"].extend(result[\"profiles\"])\n",
    "                remaining -= generated_count # Decrease remaining by actual count generated\n",
    "                total_generated = len(all_profiles[\"profiles\"])\n",
    "\n",
    "                print(f\"+++ Added {generated_count} profiles. Total: {total_generated}/{total_profiles} (Remaining: {remaining})\")\n",
    "\n",
    "                # Reset batch size tracker upon success? Optional, could speed up if failures were temporary\n",
    "                # current_batch_size_tracker = batch_size\n",
    "\n",
    "                # --- Intermediate Save Logic ---\n",
    "                # Save every 5 batches OR when crossing a 500-profile milestone OR if it's the last batch (implicitly covered by loop ending)\n",
    "                if batch_count % 5 == 0 or (total_generated // 500 > (total_generated - generated_count) // 500):\n",
    "                    temp_json_path = f\"{output_prefix}_intermediate_{total_generated}.json\"\n",
    "                    try:\n",
    "                        with open(temp_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                            json.dump(all_profiles, f, ensure_ascii=False, indent=2)\n",
    "                        print(f\"--- Saved intermediate result to {temp_json_path}\")\n",
    "                    except IOError as e:\n",
    "                        print(f\"!!! Error saving intermediate file {temp_json_path}: {e}\")\n",
    "\n",
    "                # --- Delay ---\n",
    "                time.sleep(1) # Brief pause between successful calls\n",
    "\n",
    "            else:\n",
    "                # API call succeeded but returned 0 profiles\n",
    "                print(f\"--- Batch {batch_count} generated 0 profiles despite successful API call. Retrying...\")\n",
    "                time.sleep(5) # Wait longer before retrying if 0 profiles returned\n",
    "\n",
    "        else:\n",
    "            # API call failed, returned invalid data, or salvage failed\n",
    "            print(f\"!!! Failed to generate batch {batch_count} or received invalid response.\")\n",
    "            # Reduce batch size significantly for the next attempt\n",
    "            current_batch_size_tracker = max(10, current_batch_size_tracker // 2) # Min batch size of 10\n",
    "            print(f\"--- Reduced batch size for next attempt to: {current_batch_size_tracker}\")\n",
    "            time.sleep(10) # Longer pause after a failure\n",
    "\n",
    "    print(\"\\n===== Generation Loop Finished =====\")\n",
    "    return all_profiles\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# 6) Save Final Results Function\n",
    "# --------------------\n",
    "def save_final_results(final_data, total_target: int, output_prefix: str):\n",
    "    \"\"\"Saves the final generated profiles to JSON and CSV.\"\"\"\n",
    "\n",
    "    if not final_data or \"profiles\" not in final_data or not final_data[\"profiles\"]:\n",
    "        print(\"!!! No valid final data to save.\")\n",
    "        return\n",
    "\n",
    "    actual_profiles = final_data[\"profiles\"]\n",
    "    actual_count = len(actual_profiles)\n",
    "\n",
    "    # Ensure we don't save more than requested (if generation overshot somehow)\n",
    "    if actual_count > total_target:\n",
    "        print(f\"--- Note: Generated {actual_count} profiles, trimming to target {total_target}.\")\n",
    "        actual_profiles = actual_profiles[:total_target]\n",
    "        actual_count = len(actual_profiles)\n",
    "        final_data = {\"profiles\": actual_profiles} # Update dict to save correctly\n",
    "\n",
    "    json_path = f\"{output_prefix}_final_{actual_count}.json\"\n",
    "    csv_path = f\"{output_prefix}_final_{actual_count}.csv\"\n",
    "\n",
    "    print(f\"\\n--- Saving final {actual_count} profiles ---\")\n",
    "\n",
    "    # (A) Save JSON\n",
    "    try:\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"Saved JSON to {json_path}\")\n",
    "    except IOError as e:\n",
    "        print(f\"!!! Error saving final JSON file {json_path}: {e}\")\n",
    "\n",
    "    # (B) Convert to DataFrame and Save CSV\n",
    "    try:\n",
    "        df = pd.DataFrame(actual_profiles)\n",
    "        # Reorder columns based on expected schema\n",
    "        df = df[EXPECTED_COLUMNS] # Use the list defined earlier\n",
    "        df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\") # utf-8-sig for Excel compatibility\n",
    "        print(f\"Saved CSV to {csv_path}\")\n",
    "    except KeyError as e:\n",
    "         print(f\"!!! Error creating CSV: Missing column {e}. CSV might be incomplete or incorrect.\")\n",
    "         # Optionally save with available columns:\n",
    "         # pd.DataFrame(actual_profiles).to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "         # print(f\"Saved CSV to {csv_path} with available columns.\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Error saving final CSV file {csv_path}: {e}\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# 7) Continue from Intermediate Function\n",
    "# --------------------\n",
    "def continue_from_intermediate(intermediate_json_path: str, total_profiles: int, batch_size: int, source_df: pd.DataFrame, num_examples_per_batch: int, output_prefix: str):\n",
    "    \"\"\"\n",
    "    Loads profiles from an intermediate JSON file and continues generation.\n",
    "    \"\"\"\n",
    "    all_profiles = {\"profiles\": []}\n",
    "    current_count = 0\n",
    "\n",
    "    # --- Load Existing Data ---\n",
    "    if os.path.exists(intermediate_json_path):\n",
    "        try:\n",
    "            with open(intermediate_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                loaded_data = json.load(f)\n",
    "            # Validate loaded data structure\n",
    "            if isinstance(loaded_data, dict) and \"profiles\" in loaded_data and isinstance(loaded_data[\"profiles\"], list):\n",
    "                all_profiles = loaded_data\n",
    "                current_count = len(all_profiles[\"profiles\"])\n",
    "                print(f\"--- Successfully loaded {current_count} profiles from {intermediate_json_path}\")\n",
    "            else:\n",
    "                print(f\"!!! Invalid format in {intermediate_json_path}. Starting from scratch.\")\n",
    "                all_profiles = {\"profiles\": []} # Reset\n",
    "                current_count = 0\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"!!! Invalid JSON in {intermediate_json_path}. Starting from scratch.\")\n",
    "            all_profiles = {\"profiles\": []}\n",
    "            current_count = 0\n",
    "        except Exception as e:\n",
    "            print(f\"!!! Error loading intermediate file {intermediate_json_path}: {e}. Starting from scratch.\")\n",
    "            all_profiles = {\"profiles\": []}\n",
    "            current_count = 0\n",
    "    else:\n",
    "        print(f\"--- Intermediate file {intermediate_json_path} not found. Starting from scratch.\")\n",
    "\n",
    "    # --- Check if More Profiles Needed ---\n",
    "    if current_count >= total_profiles:\n",
    "        print(f\"Already have {current_count} profiles (target was {total_profiles}). No need to generate more.\")\n",
    "        return all_profiles # Return loaded data\n",
    "\n",
    "    # --- Continue Generation ---\n",
    "    remaining = total_profiles - current_count\n",
    "    print(f\"--- Continuing generation for the remaining {remaining} profiles...\")\n",
    "\n",
    "    batch_count = (current_count // batch_size) # Estimate starting batch number\n",
    "    current_batch_size_tracker = batch_size # Reset adaptive batch size for continuation\n",
    "\n",
    "    while remaining > 0:\n",
    "        batch_count += 1\n",
    "        current_batch_size = min(current_batch_size_tracker, remaining)\n",
    "\n",
    "        print(f\"\\n===== Generating Batch {batch_count} (Continuation) =====\")\n",
    "        print(f\"Target for this batch: {current_batch_size} profiles (using {num_examples_per_batch} examples)\")\n",
    "\n",
    "        # Call API for the batch\n",
    "        result = call_gpt_function_call_batch(current_batch_size, source_df, num_examples_per_batch)\n",
    "\n",
    "        if result and \"profiles\" in result and isinstance(result[\"profiles\"], list):\n",
    "            generated_count = len(result[\"profiles\"])\n",
    "            if generated_count > 0:\n",
    "                all_profiles[\"profiles\"].extend(result[\"profiles\"])\n",
    "                # Update counts *after* extending\n",
    "                new_total_generated = len(all_profiles[\"profiles\"])\n",
    "                remaining = total_profiles - new_total_generated # Recalculate remaining\n",
    "                print(f\"+++ Added {generated_count} profiles. Total: {new_total_generated}/{total_profiles} (Remaining: {remaining})\")\n",
    "\n",
    "                # --- Intermediate Save Logic (same as in generate_large_population) ---\n",
    "                if batch_count % 5 == 0 or (new_total_generated // 500 > current_count // 500): # Check milestone crossing\n",
    "                    temp_json_path = f\"{output_prefix}_intermediate_{new_total_generated}.json\"\n",
    "                    try:\n",
    "                        with open(temp_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                            json.dump(all_profiles, f, ensure_ascii=False, indent=2)\n",
    "                        print(f\"--- Saved intermediate result to {temp_json_path}\")\n",
    "                    except IOError as e:\n",
    "                        print(f\"!!! Error saving intermediate file {temp_json_path}: {e}\")\n",
    "\n",
    "                # Update current_count for the next milestone check\n",
    "                current_count = new_total_generated\n",
    "\n",
    "                time.sleep(1) # Brief pause\n",
    "\n",
    "            else:\n",
    "                print(f\"--- Batch {batch_count} generated 0 profiles despite successful API call. Retrying...\")\n",
    "                time.sleep(5) # Wait longer\n",
    "\n",
    "        else:\n",
    "            # Failure\n",
    "            print(f\"!!! Failed to generate batch {batch_count} or received invalid response.\")\n",
    "            current_batch_size_tracker = max(10, current_batch_size_tracker // 2)\n",
    "            print(f\"--- Reduced batch size for next attempt to: {current_batch_size_tracker}\")\n",
    "            time.sleep(10) # Longer pause after failure\n",
    "\n",
    "    print(\"\\n===== Continuation Loop Finished =====\")\n",
    "    return all_profiles\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# 8) Main Execution Block\n",
    "# --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    TARGET_TOTAL_PROFILES = 5000    # Total number of profiles to generate\n",
    "    BATCH_SIZE = 200                 # Initial number of profiles per API call (will adapt on failure)\n",
    "    NUM_FEW_SHOT_EXAMPLES = 150      # Number of dynamic examples per API call\n",
    "    OUTPUT_FILE_PREFIX = \"dynamic_population\" # Prefix for output JSON/CSV files\n",
    "    INTERMEDIATE_FILE_TO_CONTINUE = \"dynamic_population_intermediate_10102.json\" # Set to None or \"\" to always start fresh\n",
    "\n",
    "    print(\"===== Synthetic Population Generation Script =====\")\n",
    "    print(f\"Target: {TARGET_TOTAL_PROFILES} profiles\")\n",
    "    print(f\"Initial Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"Few-shot Examples per Batch: {NUM_FEW_SHOT_EXAMPLES}\")\n",
    "    print(f\"Source CSV: {SOURCE_CSV_PATH}\")\n",
    "    print(f\"Output Prefix: {OUTPUT_FILE_PREFIX}\")\n",
    "\n",
    "\n",
    "    # --- Load Source Data for Few-Shot Examples ---\n",
    "    try:\n",
    "        print(f\"\\n--- Loading source data from {SOURCE_CSV_PATH}...\")\n",
    "        # Assuming the CSV has a header row (header=0)\n",
    "        # keep_default_na=False helps if empty strings are meaningful\n",
    "        source_dataframe = pd.read_csv(SOURCE_CSV_PATH, header=0, keep_default_na=False, dtype=str) # Read all as string initially for flexibility\n",
    "         # Basic Validation: Check if expected columns exist\n",
    "        missing_cols = [col for col in EXPECTED_COLUMNS if col not in source_dataframe.columns]\n",
    "        if missing_cols:\n",
    "             raise ValueError(f\"Source CSV is missing required columns: {', '.join(missing_cols)}\")\n",
    "\n",
    "        # Attempt to convert potentially numeric columns needed for mapping back to numeric types\n",
    "        # This is important because the mapping dictionaries use integer keys\n",
    "        numeric_cols = [\"Gender\", \"Homeincome\", \"Hometype\", \"CarOwn\", \"Driver\", \"Workdays\", \"Worktype\", \"Student\", \"NumHH\", \"KidinHH\"]\n",
    "        for col in numeric_cols:\n",
    "             if col in source_dataframe.columns:\n",
    "                  # errors='coerce' will turn uncastable values into NaN, which might need handling later\n",
    "                  # or use errors='raise' to stop if conversion fails\n",
    "                  source_dataframe[col] = pd.to_numeric(source_dataframe[col], errors='coerce')\n",
    "                  # Optional: Handle NaNs created by coercion if necessary, e.g., fillna or dropna\n",
    "                  if source_dataframe[col].isnull().any():\n",
    "                      print(f\"--- Warning: Column '{col}' contained non-numeric values after loading. Coerced to NaN.\")\n",
    "                      # Example: Drop rows with NaN in critical fields if needed\n",
    "                      # source_dataframe.dropna(subset=[col], inplace=True)\n",
    "\n",
    "        print(f\"Loaded {len(source_dataframe)} rows from source data.\")\n",
    "\n",
    "        if len(source_dataframe) < NUM_FEW_SHOT_EXAMPLES:\n",
    "             print(f\"--- Warning: Source data ({len(source_dataframe)} rows) is smaller than the requested number of few-shot examples ({NUM_FEW_SHOT_EXAMPLES}). Will use all available rows.\")\n",
    "             NUM_FEW_SHOT_EXAMPLES = len(source_dataframe) # Adjust dynamically\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"!!! FATAL ERROR: Source CSV file not found at {SOURCE_CSV_PATH}\")\n",
    "        exit() # Stop execution if source data is missing\n",
    "    except ValueError as ve:\n",
    "         print(f\"!!! FATAL ERROR: Problem with source CSV data: {ve}\")\n",
    "         exit()\n",
    "    except Exception as e:\n",
    "        print(f\"!!! FATAL ERROR: Failed to load or process source CSV {SOURCE_CSV_PATH}: {e}\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "    # --- Start or Continue Generation ---\n",
    "    final_population_data = None\n",
    "    if INTERMEDIATE_FILE_TO_CONTINUE and os.path.exists(INTERMEDIATE_FILE_TO_CONTINUE):\n",
    "        print(f\"\\n--- Attempting to continue generation from: {INTERMEDIATE_FILE_TO_CONTINUE} ---\")\n",
    "        final_population_data = continue_from_intermediate(\n",
    "            intermediate_json_path=INTERMEDIATE_FILE_TO_CONTINUE,\n",
    "            total_profiles=TARGET_TOTAL_PROFILES,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            source_df=source_dataframe,\n",
    "            num_examples_per_batch=NUM_FEW_SHOT_EXAMPLES,\n",
    "            output_prefix=OUTPUT_FILE_PREFIX\n",
    "        )\n",
    "    else:\n",
    "        if INTERMEDIATE_FILE_TO_CONTINUE:\n",
    "             print(f\"\\n--- Intermediate file not found ({INTERMEDIATE_FILE_TO_CONTINUE}). Starting new generation. ---\")\n",
    "        else:\n",
    "             print(\"\\n--- Starting new generation (no intermediate file specified). ---\")\n",
    "\n",
    "        final_population_data = generate_large_population(\n",
    "            total_profiles=TARGET_TOTAL_PROFILES,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            source_df=source_dataframe,\n",
    "            num_examples_per_batch=NUM_FEW_SHOT_EXAMPLES,\n",
    "            output_prefix=OUTPUT_FILE_PREFIX\n",
    "        )\n",
    "\n",
    "    # --- Save Final Results ---\n",
    "    if final_population_data and \"profiles\" in final_population_data:\n",
    "        final_count = len(final_population_data[\"profiles\"])\n",
    "        if final_count >= TARGET_TOTAL_PROFILES:\n",
    "            print(f\"\\n==== Generation Complete. Achieved target of {TARGET_TOTAL_PROFILES} (generated {final_count}). ====\")\n",
    "        else:\n",
    "             print(f\"\\n==== Generation Finished. Generated {final_count} profiles (target was {TARGET_TOTAL_PROFILES}). ====\")\n",
    "\n",
    "        save_final_results(final_population_data, TARGET_TOTAL_PROFILES, OUTPUT_FILE_PREFIX)\n",
    "    else:\n",
    "        print(\"\\n==== Failed to generate population data or the final result was invalid. ====\")\n",
    "\n",
    "    print(\"===== Script Finished =====\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
